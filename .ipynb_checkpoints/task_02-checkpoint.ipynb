{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Хороший шаблон](https://twitter.com/dsunderhood/status/1371874842664910849), который можно использовать, \n",
    "когда ваш ноутбук предстоит показать кому-то ещё \n",
    "(ну или посмотреть самим через 2 недели).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кратко об этом исследовании\n",
    "Данные из Остинского центра животных, то есть приюта, -- с 1 октября 2013 по **март 2016**. \n",
    "\n",
    "### Цель\n",
    "\n",
    "Требуется предсказать судьбу каждого животного по данным о нём сведениям. По сути, обычная задача категоризации. Классы: Adoption, Died, Euthanasia, Return to owner, Transfer. \n",
    "\n",
    "Все классы считаем одинаково важными все зависимости от представленности в выборке. Качество предсказаний оценивается поэтому с помощью macro-averaged F1 score.\n",
    "\n",
    "---\n",
    "\n",
    "**Задание**\n",
    "\n",
    "Пользоваться в точности предложенной в этом шаблоне схемой необязательно, но в этом ноутбуке должен быть \n",
    "- внятный и чистый, \n",
    "- прокомментированный, \n",
    "- воспроизводимый (зафиксируйте все random seeds, которые возможно),\n",
    "- мотивированный\n",
    "**код**, который **генерирует ваше лучшее решение**.\n",
    "\n",
    "А также пока **неформальный отчёт** о проделанной работе.\n",
    "\n",
    "\n",
    "### Методы\n",
    "\n",
    "`TODO: Напишите, как пробовали предобрабатывать признаки`\n",
    "\n",
    "`TODO:Напишите, какие модели и с какими параметрами вы пробовали`\n",
    "\n",
    "\n",
    "### Результаты\n",
    "\n",
    "`TODO: Поделитесь наблюдениями, историями успеха и зря потраченными усилиями; что интересного можете сказать о наборе данных? какие выводы?`\n",
    "\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конфиги и константы\n",
    "(пожалуйста, без волшебных чисел в коде)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME2LABEL = {\"Adoption\" : 0, \n",
    "                 \"Transfer\": 1, \n",
    "                 \"Return_to_owner\": 2, \n",
    "                 \"Euthanasia\": 3, \n",
    "                 \"Died\": 4\n",
    "                }\n",
    "LABEL2OUTCOME = {v: k for k,v in OUTCOME2LABEL.items()}\n",
    "FOLD_K = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки\n",
    "(все импорты желательно должны быть здесь)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.0'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import eli5\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\", encoding=\"utf-8\")\n",
    "df_test = pd.read_csv(\"test.csv\", encoding=\"utf-8\")\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка признаков\n",
    "\n",
    "#### Даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_dates2number(date_series: pd.Series):\n",
    "    return pd.to_datetime(date_series).values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "pandas_dates2number(pd.Series([\"2020-12-10\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Возраст\n",
    "\n",
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Цвета и породы\n",
    "\n",
    "Повторяющихся категорий много, так что можно закодировать их и так, однако **некоторые из них можно и растащить на части**\n",
    "\n",
    "Необязательно, но можете попробовать, вдруг поможет :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Color\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подсказка: CountVectorizer\n",
    "Прошу любить и жаловать: векторизация текста из коробки. \n",
    "\n",
    "Откройте документацию, если не сталкивались: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorized_color = vectorizer.fit_transform(df_train[\"Color\"])\n",
    "\n",
    "# А много ли получилось слов, описывающих цвета?\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "vectorized_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть можно векторизовать колонку, а потом эти признаки добавить в общей матрице признаков. Обратите внимание, что если мы к трейну применяем `fit_transform`, то к тесту нужно применить **тот же самый объект-векторизатор** и его метод `transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пол\n",
    "\n",
    "Пола, как мы видим, четыре: стерилизованные и нестерилизованные самки и самцы. Также пол может быть неизвестен.\n",
    "\n",
    "Может, факт стерилизации стоит сделать отдельным признаком? Но это неточно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"SexuponOutcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Подсказка: OrdinalEncoder\n",
    "\n",
    "Давайте на примере пола животного и чего-нибудь ещё опробуем OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "ordinal_encoder.fit(df_train[[\"AnimalType\", \"Color\"]])\n",
    "ordinal_encoder.transform(df_train[[\"AnimalType\", \"Color\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая колонка закодировалась нулями и единицами (потому что видов животных всего два).\n",
    "\n",
    "Вторая -- идентификаторами многих уникальных значений поля \"Color\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Единая матрица признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, oh_encoder=None):\n",
    "    \n",
    "    columns_categorical = [\"AnimalType\", \"SexuponOutcome\"]\n",
    "    \n",
    "    if oh_encoder is None:\n",
    "        oh_encoder = OneHotEncoder(handle_unknown='ignore') # неизвестные значения на тесте будем игнорировать\n",
    "        oh_encoder.fit(df[columns_categorical])\n",
    "    \n",
    "    encoded_categorical_features = oh_encoder.transform(df[columns_categorical])\n",
    "    cat_feature_names = oh_encoder.get_feature_names(columns_categorical)\n",
    "    \n",
    "    # todo: Огромные числа, которые явно требуют масштабирования/нормализации, right? :) \n",
    "    # todo: (ну, как минимум если у вас линейные модели с регуляризаторами) \n",
    "    # todo: E.g. если будете вычитать среднее, не забывайте, что из тестовых данных \n",
    "    # todo: надо вычесть то же число (то есть придётся сохранить на трейне и передать на тест)! \n",
    "    dates = pandas_dates2number(df[\"DateTime\"])\n",
    "    dates = dates[:, np.newaxis] # делаем массив \"двумерным\" для последующей склейки\n",
    "    \n",
    "    X = sparse.hstack([encoded_categorical_features, dates])    \n",
    "    \n",
    "    return X, list(cat_feature_names) + [\"date\"], oh_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, fnames, ohe_hot_encoder = prepare_features(df_train)\n",
    "y_train = df_train[\"Outcome\"]\n",
    "X_test, _, _  = prepare_features(df_test, ohe_hot_encoder)\n",
    "\n",
    "X_train.shape, X_test.shape, np.array(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы ещё будем об этом говорить, но в первом приближении советы такие: \n",
    "- если разреженные нормализованные признаки (например, если у вас один сплошной OneHotEncoding), есть смысл брать линейные модели;\n",
    "- если признаков немного (не тысячи), и они, к примеру, даже не нормализованы, есть смысл использовать логические классификаторы -- например, деревья и ансамбли на их основе;\n",
    "- усреднение/голосование/взвешенное голосование результатов моделей с разными пространствами решений может дать хороший прирост в качестве.\n",
    "\n",
    "Но всё это с оговорками, конечно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Какие параметры ещё важны для перебора для выбранной вами модели?\n",
    "\n",
    "param_grid = [\n",
    "    {\"min_samples_leaf\": [1, 2, 5],\n",
    "     \"min_samples_split\": [2, 5, 10],\n",
    "     \"max_depth\": [3, 5, 10],\n",
    "     \"criterion\": [\"gini\", \"entropy\"]}]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\"f1_macro\", \"f1_micro\"]\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    print(\"# Tuning for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    # поиск по заданной решётке параметров\n",
    "    clf = GridSearchCV(tree.DecisionTreeClassifier(random_state=100, class_weight=\"balanced\"),\n",
    "                       param_grid, \n",
    "                       scoring=score, \n",
    "                       verbose=1, \n",
    "                       # if the estimator is a classifier and y is [...] multiclass, StratifiedKFold is used\n",
    "                       cv=FOLD_K) \n",
    "\n",
    "    # запускаем поиск\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best params on dev set:\")\n",
    "    print(clf.best_params_)\n",
    "    \n",
    "    print(\"Scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "    # обучаем на всём с \"лучшими\" параметрами\n",
    "    best_estimator = clf.best_estimator_\n",
    "    best_estimator.fit(X_train, y_train)\n",
    "    \n",
    "    # порождаем и сохраняем сабмит\n",
    "    y_pred = best_estimator.predict(X_test)\n",
    "    pd.DataFrame({\"ID\": df_test[\"ID\"], \"Outcome\": y_pred}).to_csv(\"submission_\" + score + \".csv\", index=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бонус: интервью модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.explain_weights(best_estimator, target_names=LABEL2OUTCOME, feature_names=fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
